{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Traditional_ML.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMaPkvsXC2DiyQ94pZ4sdUh",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/chumpblocckami/AmazonTextClustering/blob/master/Traditional_ML_from_scratch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0FGvl4Iagq1e"
      },
      "source": [
        "import random\n",
        "import math\n",
        "import numpy as np\n",
        "from matplotlib.pyplot import cm\n",
        "from sklearn.decomposition import PCA\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KYzJPyWYjGJF"
      },
      "source": [
        "## 1. Clustering\n",
        "Based on a n-dimensional matrix, we need to find cluster of similar data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t-0unuGVjAYR"
      },
      "source": [
        "data = [[random.randint(1,100) for x in range(0,2)] for x in range(0,100)]\n",
        "\n",
        "class KMeans():\n",
        "  def __init__(self, data, n_cluster=3, k=10):\n",
        "    self.data = data\n",
        "    self.n_clusters = n_cluster\n",
        "    self.k = k\n",
        "    self.centroids = self.init_centroids()\n",
        "    self.labels = {}\n",
        "\n",
        "\n",
        "  def init_centroids(self):\n",
        "    \"init centroids\"\n",
        "    dims = len(self.data[0])\n",
        "    upper_limits = []\n",
        "    lower_limits = []\n",
        "    for dim in range(dims):\n",
        "      dim_max = 0\n",
        "      dim_min = 9**99\n",
        "      for feature in data:\n",
        "          if feature[dim] > dim_max:\n",
        "            dim_max = feature[dim]\n",
        "          if feature[dim] < dim_min:\n",
        "            dim_min = feature[dim]\n",
        "      upper_limits.append(dim_max)\n",
        "      lower_limits.append(dim_min)\n",
        "    assert len(upper_limits) == len(upper_limits)\n",
        "    centroids = []\n",
        "    for n in range(self.n_clusters):\n",
        "        centroid = [random.randint(lower_limits[x],upper_limits[x]) for x in range(dims)]\n",
        "        centroids.append(centroid)\n",
        "    return centroids\n",
        "\n",
        "  def prepare_data(self):\n",
        "    \"check data integrity\"\n",
        "    return self.data\n",
        "\n",
        "  def create_centroids(self):\n",
        "    \"based on the data, create two centroids\"\n",
        "\n",
        "  def get_distance(self,a,b):\n",
        "    \"return distance between two points\"\n",
        "    a = (x for x in a)\n",
        "    b = (x for x in b)\n",
        "    distance = math.sqrt(sum( (a - b)**2 for a, b in zip(a,b)))\n",
        "    return distance\n",
        "\n",
        "  def get_best_fit(self):\n",
        "    \"based on n centroids, search best fit\"\n",
        "    #for every point, get the distances from specific cluster\n",
        "    distances = []\n",
        "    for point in data:\n",
        "      _distances = []\n",
        "      for centroid in self.centroids:\n",
        "        distance_point_centroids = self.get_distance(point,centroid)\n",
        "        _distances.append(distance_point_centroids) \n",
        "      distances.append(_distances)\n",
        "\n",
        "    #based on distance, assign a point to a centroids\n",
        "    self.labels = {}\n",
        "    for n,distance in enumerate(distances):\n",
        "      label = distance.index(min(distance))\n",
        "      if str(label) not in self.labels.keys():\n",
        "        self.labels[str(label)] = [data[n]]\n",
        "      else:\n",
        "        self.labels[str(label)].append(data[n]) \n",
        "    \n",
        "    #update centroids of a given class with the mean\n",
        "    for label in self.labels.keys():\n",
        "      _data = self.labels[label]\n",
        "      avg = [float(sum(col))/len(col) for col in zip(*_data)]\n",
        "      self.centroids[int(label)] = avg\n",
        "  \n",
        "  def plot_clusters(self,k):\n",
        "    \"plot clusters\"\n",
        "    pca = PCA(n_components=2)\n",
        "    _data = pca.fit_transform(self.data)\n",
        "    _centroids = pca.fit_transform(self.centroids)\n",
        "\n",
        "    plt.figure()\n",
        "    plt.title(str(k) + \" iteration\")\n",
        "\n",
        "    color=iter(cm.rainbow(np.linspace(0,1,self.n_clusters)))\n",
        "    color = list(color)\n",
        "    if self.labels == {}:\n",
        "          colors = \"gray\"\n",
        "    else:\n",
        "          colors = []\n",
        "          for point in self.data:\n",
        "            for cluster in self.labels.keys():\n",
        "              if point in self.labels[cluster]:\n",
        "                colors.append(color[int(cluster)])\n",
        "        \n",
        "    plt.scatter([x[0] for x in _data], [y[1] for y in _data],c=colors)\n",
        "\n",
        "    c_colors = [color[self.centroids.index(x)] for x in self.centroids]\n",
        "    plt.scatter([x[0] for x in _centroids], [y[1] for y in _centroids],c=c_colors,marker=\"*\",edgecolors=\"black\",s=100)\n",
        "\n",
        "\n",
        "  def iter(self,plot=True):\n",
        "    \"iterate clustering\"\n",
        "    for k in range(self.k):\n",
        "      if plot:\n",
        "        self.plot_clusters(k)\n",
        "      self.get_best_fit()\n",
        "\n",
        "\n",
        "  def fit(self):\n",
        "    self.prepare_data()\n",
        "\n",
        "  def transform(self):\n",
        "    self.iter()\n",
        "\n",
        "  def fit_transform(self):\n",
        "    self.fit()\n",
        "    self.transform()\n",
        "\n",
        "kmeans = KMeans(data)\n",
        "kmeans.fit_transform()\n",
        "\n",
        "print(kmeans.labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zSnwp1BVw5-n"
      },
      "source": [
        "2. KNeighbours"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0wvqfCILw5kq",
        "outputId": "a713cdbc-a2b9-4f9e-eb11-38fc7595c67f"
      },
      "source": [
        "import copy\n",
        "from collections import Counter\n",
        "\n",
        "class Kneighbours():\n",
        "  def __init__(self,data,labels,k):\n",
        "    self.data = data\n",
        "    self.labels = labels\n",
        "    self.k = k\n",
        "    self.distances = {}\n",
        "    self.prediction_space = {}\n",
        "    self.predicted_labels = {}\n",
        "\n",
        "  def get_distance(self,a,b):\n",
        "    \"return distance between two points\"\n",
        "    a = (x for x in a)\n",
        "    b = (x for x in b)\n",
        "    distance = math.sqrt(sum( (a - b)**2 for a, b in zip(a,b)))\n",
        "    return distance\n",
        "  \n",
        "  def get_k_neighbours(self):\n",
        "    for n,point in enumerate(data):\n",
        "      min_distances = [self.get_distance(point,x) for x in data]\n",
        "      distances = copy.deepcopy(min_distances)\n",
        "      distances.sort()\n",
        "      distances = distances[:self.k]\n",
        "      self.distances[n] = {min_distances.index(dist):dist for dist in distances}\n",
        "      self.prediction_space[n] = [self.labels[lbl] for lbl in self.distances[n].keys()]\n",
        "    \n",
        "  def predict(self,point):\n",
        "    min_distances = [self.get_distance(point,x) for x in data]\n",
        "    distances = copy.deepcopy(min_distances)\n",
        "    distances.sort()\n",
        "    distances = distances[:self.k]\n",
        "    label_space = Counter([self.labels[min_distances.index(dist)] for dist in distances])\n",
        "    prediction = {key:values/sum(label_space.values()) for key,values in label_space.items()}\n",
        "    return prediction\n",
        "\n",
        "  def iter(self,data):\n",
        "    self.predicted_labels = {}\n",
        "    if isinstance(data[0],list):\n",
        "      predictions = []\n",
        "      for n,point in enumerate(data):\n",
        "        prediction = self.predict(point)\n",
        "        predictions.append(prediction)\n",
        "      self.predicted_labels.update({n:predictions})\n",
        "    else:\n",
        "      self.predicted_labels = self.predict(data)\n",
        "\n",
        "  def fit(self):\n",
        "    self.get_k_neighbours()\n",
        "\n",
        "  def transform(self,data):\n",
        "    self.iter(data)\n",
        "  \n",
        "data = [[1,1,1,1,1],\n",
        "        [1,1,1,1,2],\n",
        "        [1,1,1,10,1],\n",
        "        [1,1,1,11,1]]\n",
        "labels = [0,0,1,1]\n",
        "\n",
        "KNN = Kneighbours(data,labels,k=3)\n",
        "KNN.fit()\n",
        "print(KNN.distances)\n",
        "\n",
        "print(\"to predict:\",[[1,1,1,1,1]])\n",
        "preds = KNN.transform([[1,1,1,1,1],[2,2,2,2,2]])\n",
        "print(KNN.predicted_labels)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{0: {0: 0.0, 1: 1.0, 2: 9.0}, 1: {1: 0.0, 0: 1.0, 2: 9.055385138137417}, 2: {2: 0.0, 3: 1.0, 0: 9.0}, 3: {3: 0.0, 2: 1.0, 0: 10.0}}\n",
            "to predict: [[1, 1, 1, 1, 1]]\n",
            "{1: [{0: 0.6666666666666666, 1: 0.3333333333333333}, {0: 0.6666666666666666, 1: 0.3333333333333333}]}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z6Qttk7UF69F",
        "outputId": "84cc6e84-40f7-47a5-954f-21a14ca59216"
      },
      "source": [
        "ciao = [1,1,1,2,3,2]\n",
        "from collections import Counter\n",
        "{k:v/sum(Counter(ciao).values()) for k,v in Counter(ciao).items()}\n",
        "#max(Counter(ciao), key=Counter(ciao).get)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{1: 0.5, 2: 0.3333333333333333, 3: 0.16666666666666666}"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q2q9Vse4jR41"
      },
      "source": [
        "3. Decision Trees"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Elkw21_si-ve"
      },
      "source": [
        "data = [[1,1,1,1,1],\n",
        "        [1,1,1,1,2],\n",
        "        [1,1,1,10,1],\n",
        "        [1,1,1,10,1]]\n",
        "labels = [0,0,1,1]\n",
        "\n",
        "class DecisionTrees():\n",
        "  def __init__(self, data,labels):\n",
        "    self.data = data\n",
        "    self.labels = labels\n",
        "\n",
        "  def get_gini(self,groups,class):\n",
        "    instances = float([sum(len(group)) for group in groups])\n",
        "    gini = 0\n",
        "    for group in groups:\n",
        "      size = float(len(group))\n",
        "      score = 0\n",
        "      for _class in classes:\n",
        "        p = [x[-1] for x in group].count(_class) / size\n",
        "        score += p * p\n",
        "      gini += (1 - score) * (size/instances)\n",
        "   return gini"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}